# üß† H∆∞·ªõng d·∫´n t√≠ch h·ª£p Interpretation v√†o c√°c trang

## üìã T·ªïng quan

File `utils/interpretation.py` cung c·∫•p c√°c components gi·∫£i th√≠ch k·∫øt qu·∫£ cho ng∆∞·ªùi kh√¥ng chuy√™n:

### ‚úÖ ƒê√£ t·∫°o:
- ‚úÖ `utils/interpretation.py` - Core interpretation library
- ‚úÖ `pages/6_Interpretation_Report.py` - Standalone interpretation page
- üîÑ Ch·ªù t√≠ch h·ª£p v√†o 5 trang c√≤n l·∫°i

---

## üéØ Components c√≥ s·∫µn

### 1. ResultVisualizer
```python
from utils.interpretation import ResultVisualizer

visualizer = ResultVisualizer()

# So s√°nh ·∫£nh tr∆∞·ªõc/sau
visualizer.compare_images(
    img_before=original,
    img_after=processed,
    title_before="·∫¢nh g·ªëc",
    title_after="·∫¢nh ƒë√£ x·ª≠ l√Ω",
    description="Gi·∫£i th√≠ch cho ng∆∞·ªùi kh√¥ng chuy√™n"
)

# Overlay ph√¢n ƒëo·∫°n v·ªõi ch√∫ th√≠ch
labels = {
    1: "Kh·ªëi u nghi ng·ªù",
    2: "M√¥ b√¨nh th∆∞·ªùng"
}
visualizer.show_overlay_with_legend(
    image=mri_image,
    mask=segmentation_mask,
    labels=labels,
    title="K·∫øt qu·∫£ ph√¢n ƒëo·∫°n n√£o b·ªô"
)

# Hi·ªÉn th·ªã nhi·ªÅu slices 3D
visualizer.show_3d_slices(
    volume=volume_3d,
    axis=2,
    num_slices=9,
    title="C√°c l√°t c·∫Øt MRI"
)
```

### 2. MetricsExplainer
```python
from utils.interpretation import MetricsExplainer

metrics_explainer = MetricsExplainer()

# T·ª± ƒë·ªông gi·∫£i th√≠ch metrics
explanation = metrics_explainer.explain_metric('PSNR', 35.2)
# Returns: {
#     'name': 'ƒê·ªô r√µ n√©t (PSNR)',
#     'value': 35.2,
#     'unit': 'dB',
#     'assessment': 'good',
#     'description': '...',
#     'interpretation': 'Ch·∫•t l∆∞·ª£ng t·ªët'
# }

# Dashboard metrics v·ªõi m√†u s·∫Øc
metrics = {
    'PSNR': 35.2,
    'SSIM': 0.94,
    'Dice': 0.87
}
metrics_explainer.show_metrics_dashboard(
    metrics,
    title="Ch·ªâ s·ªë ch·∫•t l∆∞·ª£ng"
)
```

### 3. InterpretationGenerator
```python
from utils.interpretation import InterpretationGenerator

# T·∫°o ƒëo·∫°n gi·∫£i th√≠ch t·ª± ƒë·ªông
interpretation = InterpretationGenerator.generate_interpretation(
    task_type='segmentation',  # ho·∫∑c 'preprocessing', 'reconstruction', 'anonymization'
    metrics={'Dice': 0.87, 'IoU': 0.76},
    image_info={'region_percentage': 15.3}
)

# Ho·∫∑c d√πng helper function
from utils.interpretation import show_interpretation_section

show_interpretation_section(
    task_type='preprocessing',
    metrics={'PSNR': 35.2, 'SSIM': 0.94},
    image_info={'operations': ['normalize', 'denoise', 'enhance']}
)
```

### 4. ReportBuilder
```python
from utils.interpretation import ReportBuilder

# T·∫°o b√°o c√°o PDF/HTML
report_bytes = ReportBuilder.create_interpretation_report(
    title="B√°o c√°o Ph√¢n ƒëo·∫°n MRI N√£o",
    task_type='segmentation',
    images={
        '·∫¢nh g·ªëc': original_image,
        'K·∫øt qu·∫£ ph√¢n ƒëo·∫°n': overlay_image
    },
    metrics={'Dice': 0.87, 'IoU': 0.76},
    interpretation=interpretation_text,
    output_format='pdf'  # ho·∫∑c 'html'
)

# Download
st.download_button(
    "üì• T·∫£i b√°o c√°o",
    data=report_bytes,
    file_name="report.pdf",
    mime="application/pdf"
)
```

---

## üìù T√≠ch h·ª£p v√†o t·ª´ng trang

### üé® 1. Preprocessing Page (`pages/5_Preprocessing.py`)

**V·ªã tr√≠ t√≠ch h·ª£p:** Sau khi x·ª≠ l√Ω xong ·∫£nh, tr∆∞·ªõc ph·∫ßn download

```python
# Th√™m imports
from utils.interpretation import (
    ResultVisualizer,
    MetricsExplainer,
    show_interpretation_section
)
from skimage.metrics import peak_signal_noise_ratio, structural_similarity

# Sau khi c√≥ original v√† processed
if processed_image is not None:
    
    # 1. So s√°nh tr·ª±c quan
    st.markdown("---")
    st.subheader("üîç So s√°nh k·∫øt qu·∫£")
    
    visualizer = ResultVisualizer()
    visualizer.compare_images(
        original_image,
        processed_image,
        title_before="·∫¢nh g·ªëc",
        title_after="·∫¢nh sau ti·ªÅn x·ª≠ l√Ω",
        description="·∫¢nh ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a, gi·∫£m nhi·ªÖu v√† tƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n "
                   "ƒë·ªÉ l√†m n·ªïi b·∫≠t c√°c chi ti·∫øt m√¥ v√† c·∫•u tr√∫c trong ·∫£nh y t·∫ø."
    )
    
    # 2. T√≠nh metrics
    psnr = peak_signal_noise_ratio(original_image, processed_image)
    ssim = structural_similarity(original_image, processed_image, data_range=1.0)
    mse = np.mean((original_image - processed_image) ** 2)
    
    metrics = {
        'PSNR': psnr,
        'SSIM': ssim,
        'MSE': mse
    }
    
    # 3. Dashboard metrics
    st.markdown("---")
    MetricsExplainer().show_metrics_dashboard(metrics)
    
    # 4. Gi·∫£i th√≠ch
    show_interpretation_section(
        task_type='preprocessing',
        metrics=metrics,
        image_info={'operations': selected_operations}  # list c√°c operations ƒë√£ ch·ªçn
    )
```

---

### üß† 2. Segmentation Page (`pages/2_Segmentation.py`)

**V·ªã tr√≠ t√≠ch h·ª£p:** Sau khi segmentation xong

```python
# Th√™m imports
from utils.interpretation import (
    ResultVisualizer,
    MetricsExplainer,
    show_interpretation_section
)

# Sau khi c√≥ mask
if segmentation_mask is not None:
    
    # 1. Overlay v·ªõi ch√∫ th√≠ch
    st.markdown("---")
    st.subheader("üé® K·∫øt qu·∫£ ph√¢n ƒëo·∫°n")
    
    visualizer = ResultVisualizer()
    
    labels = {
        0: "N·ªÅn (background)",
        1: "M√¥ n√£o tr·∫Øng (White Matter)",
        2: "M√¥ n√£o x√°m (Gray Matter)",
        3: "D·ªãch n√£o t·ªßy (CSF)"
    }
    
    visualizer.show_overlay_with_legend(
        image=original_brain_image,
        mask=segmentation_mask,
        labels=labels,
        title="Ph√¢n ƒëo·∫°n n√£o b·ªô t·ª± ƒë·ªông"
    )
    
    # 2. T√≠nh metrics (n·∫øu c√≥ ground truth)
    if ground_truth is not None:
        from sklearn.metrics import jaccard_score
        
        # Flatten arrays
        y_true = ground_truth.flatten()
        y_pred = segmentation_mask.flatten()
        
        # Dice coefficient
        intersection = np.sum(y_true * y_pred)
        dice = (2.0 * intersection) / (np.sum(y_true) + np.sum(y_pred))
        
        # IoU
        iou = jaccard_score(y_true, y_pred, average='macro')
        
        metrics = {
            'Dice': dice,
            'IoU': iou
        }
        
        # 3. Dashboard
        st.markdown("---")
        MetricsExplainer().show_metrics_dashboard(metrics)
    
    # 4. Gi·∫£i th√≠ch
    total_pixels = segmentation_mask.size
    region_pixels = np.sum(segmentation_mask > 0)
    region_pct = (region_pixels / total_pixels) * 100
    
    show_interpretation_section(
        task_type='segmentation',
        metrics=metrics if ground_truth else {},
        image_info={'region_percentage': region_pct}
    )
```

---

### üîÑ 3. CT Reconstruction Page (`pages/3_CT_Reconstruction.py`)

**V·ªã tr√≠ t√≠ch h·ª£p:** Sau reconstruction

```python
# Th√™m imports
from utils.interpretation import (
    ResultVisualizer,
    MetricsExplainer,
    show_interpretation_section
)
from skimage.metrics import peak_signal_noise_ratio, structural_similarity

# Sau khi c√≥ reconstructed image
if reconstructed_image is not None:
    
    # 1. So s√°nh v·ªõi ground truth (n·∫øu c√≥)
    st.markdown("---")
    st.subheader("üîç ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng t√°i t·∫°o")
    
    visualizer = ResultVisualizer()
    
    if ground_truth_image is not None:
        visualizer.compare_images(
            ground_truth_image,
            reconstructed_image,
            title_before="·∫¢nh ground truth",
            title_after="·∫¢nh t√°i t·∫°o",
            description=f"T√°i t·∫°o t·ª´ {num_angles} g√≥c qu√©t. "
                       f"√çt g√≥c qu√©t h∆°n ‚Üí nhanh h∆°n nh∆∞ng ch·∫•t l∆∞·ª£ng th·∫•p h∆°n."
        )
        
        # 2. Metrics
        psnr = peak_signal_noise_ratio(ground_truth_image, reconstructed_image)
        ssim = structural_similarity(ground_truth_image, reconstructed_image, data_range=1.0)
        mse = np.mean((ground_truth_image - reconstructed_image) ** 2)
        
        metrics = {
            'PSNR': psnr,
            'SSIM': ssim,
            'MSE': mse,
            'SNR': psnr - 10  # approximation
        }
        
        # 3. Dashboard
        st.markdown("---")
        MetricsExplainer().show_metrics_dashboard(metrics)
        
    else:
        # Ch·ªâ hi·ªÉn th·ªã reconstructed
        st.image(reconstructed_image, caption="·∫¢nh CT t√°i t·∫°o", use_container_width=True)
        metrics = {}
    
    # 4. Gi·∫£i th√≠ch
    show_interpretation_section(
        task_type='reconstruction',
        metrics=metrics,
        image_info={
            'method': reconstruction_method,  # 'FBP', 'SART', etc.
            'num_angles': num_angles
        }
    )
```

---

### üß≤ 4. MRI Reconstruction Page (`pages/4_MRI_Reconstruction.py`)

**V·ªã tr√≠ t√≠ch h·ª£p:** T∆∞∆°ng t·ª± CT Reconstruction

```python
# Th√™m imports
from utils.interpretation import (
    ResultVisualizer,
    MetricsExplainer,
    show_interpretation_section
)

# Sau reconstruction
if reconstructed_mri is not None:
    
    # 1. So s√°nh
    st.markdown("---")
    visualizer = ResultVisualizer()
    
    if ground_truth_mri is not None:
        visualizer.compare_images(
            ground_truth_mri,
            reconstructed_mri,
            title_before="MRI ƒë·∫ßy ƒë·ªß",
            title_after="MRI t√°i t·∫°o",
            description=f"T√°i t·∫°o t·ª´ k-space undersampling {sampling_rate}%. "
                       f"Undersampling cao ‚Üí qu√©t nhanh h∆°n nh∆∞ng m·∫•t th√¥ng tin."
        )
        
        # Metrics
        psnr = peak_signal_noise_ratio(ground_truth_mri, reconstructed_mri)
        ssim = structural_similarity(ground_truth_mri, reconstructed_mri, data_range=1.0)
        
        metrics = {
            'PSNR': psnr,
            'SSIM': ssim
        }
        
        MetricsExplainer().show_metrics_dashboard(metrics)
    
    # Gi·∫£i th√≠ch
    show_interpretation_section(
        task_type='reconstruction',
        metrics=metrics,
        image_info={
            'method': 'Inverse FFT with undersampled k-space',
            'sampling_rate': sampling_rate
        }
    )
```

---

### üîí 5. Anonymization Page (`pages/1_Anonymization.py`)

**V·ªã tr√≠ t√≠ch h·ª£p:** Sau anonymization

```python
# Th√™m imports
from utils.interpretation import show_interpretation_section

# Sau khi anonymize
if anonymized_success:
    
    st.success("‚úÖ ƒê√£ ·∫©n danh h√≥a th√†nh c√¥ng!")
    
    # Hi·ªÉn th·ªã metadata before/after
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Metadata g·ªëc")
        st.json({
            'PatientName': original_metadata.get('PatientName', 'N/A'),
            'PatientID': original_metadata.get('PatientID', 'N/A'),
            'PatientBirthDate': original_metadata.get('PatientBirthDate', 'N/A'),
            # ... other fields
        })
    
    with col2:
        st.subheader("Metadata sau ·∫©n danh")
        st.json({
            'PatientName': 'ANONYMIZED',
            'PatientID': 'ANONYMIZED',
            'PatientBirthDate': 'ANONYMIZED',
            # ...
        })
    
    # Gi·∫£i th√≠ch
    st.markdown("---")
    show_interpretation_section(
        task_type='anonymization',
        metrics={},
        image_info={
            'fields_removed': [
                'PatientName', 'PatientID', 'PatientBirthDate',
                'InstitutionName', 'ReferringPhysicianName'
            ]
        }
    )
```

---

## üé® Th√™m Export B√°o c√°o v√†o t·∫•t c·∫£ c√°c trang

Th√™m section n√†y v√†o cu·ªëi m·ªói trang:

```python
# ·ªû cu·ªëi trang, sau t·∫•t c·∫£ k·∫øt qu·∫£
if 'results' in st.session_state and st.session_state.results:
    
    st.markdown("---")
    st.subheader("üìÑ Xu·∫•t b√°o c√°o gi·∫£i th√≠ch")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        report_format = st.selectbox(
            "ƒê·ªãnh d·∫°ng",
            ['PDF', 'HTML']
        )
    
    with col2:
        report_title = st.text_input(
            "Ti√™u ƒë·ªÅ b√°o c√°o",
            value=f"B√°o c√°o {page_name} - {datetime.now().strftime('%Y%m%d')}"
        )
    
    with col3:
        st.write("")  # spacer
        st.write("")
        generate_report = st.button("üöÄ T·∫°o b√°o c√°o", type="primary")
    
    if generate_report:
        with st.spinner("ƒêang t·∫°o b√°o c√°o..."):
            try:
                from utils.interpretation import (
                    ReportBuilder,
                    InterpretationGenerator
                )
                
                # T·∫°o interpretation
                interpretation = InterpretationGenerator.generate_interpretation(
                    task_type=task_type,  # 'segmentation', 'preprocessing', etc.
                    metrics=metrics_dict,
                    image_info=additional_info
                )
                
                # T·∫°o b√°o c√°o
                report_bytes = ReportBuilder.create_interpretation_report(
                    title=report_title,
                    task_type=task_type,
                    images=images_dict,  # {'name': numpy_array}
                    metrics=metrics_dict,
                    interpretation=interpretation,
                    output_format=report_format.lower()
                )
                
                # Download button
                file_ext = 'pdf' if report_format == 'PDF' else 'html'
                mime_type = 'application/pdf' if report_format == 'PDF' else 'text/html'
                
                st.download_button(
                    label=f"üì• T·∫£i b√°o c√°o {report_format}",
                    data=report_bytes,
                    file_name=f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{file_ext}",
                    mime=mime_type
                )
                
                st.success(f"‚úÖ B√°o c√°o {report_format} ƒë√£ ƒë∆∞·ª£c t·∫°o!")
                
            except Exception as e:
                st.error(f"‚ùå L·ªói khi t·∫°o b√°o c√°o: {e}")
```

---

## üéØ Checklist t√≠ch h·ª£p

### ‚úÖ Phase 1: Core Components (DONE)
- [x] T·∫°o `utils/interpretation.py`
- [x] T·∫°o `pages/6_Interpretation_Report.py` (standalone demo)
- [x] Test c√°c components ho·∫°t ƒë·ªông ƒë·ªôc l·∫≠p

### üîÑ Phase 2: Integration (TODO)
- [ ] **Preprocessing** (`pages/5_Preprocessing.py`)
  - [ ] Add comparison visualization
  - [ ] Add metrics dashboard
  - [ ] Add interpretation section
  - [ ] Add PDF/HTML export

- [ ] **Segmentation** (`pages/2_Segmentation.py`)
  - [ ] Add overlay with legend
  - [ ] Add Dice/IoU metrics
  - [ ] Add interpretation section
  - [ ] Add export

- [ ] **CT Reconstruction** (`pages/3_CT_Reconstruction.py`)
  - [ ] Add comparison with ground truth
  - [ ] Add PSNR/SSIM metrics
  - [ ] Add interpretation section
  - [ ] Add export

- [ ] **MRI Reconstruction** (`pages/4_MRI_Reconstruction.py`)
  - [ ] Add comparison
  - [ ] Add metrics
  - [ ] Add interpretation
  - [ ] Add export

- [ ] **Anonymization** (`pages/1_Anonymization.py`)
  - [ ] Add metadata comparison
  - [ ] Add interpretation
  - [ ] Add export

### üß™ Phase 3: Testing
- [ ] Test t·∫•t c·∫£ visualizations
- [ ] Test metrics calculations
- [ ] Test PDF generation
- [ ] Test HTML generation
- [ ] Test v·ªõi real medical images

---

## üí° Tips

### 1. Normalize images tr∆∞·ªõc khi visualize
```python
from utils.image_utils import normalize_image

# Normalize v·ªÅ 0-1
img_normalized = normalize_image(img_array)
```

### 2. Handle 3D volumes
```python
# L·∫•y middle slice
if len(img_array.shape) == 3:
    display_image = img_array[img_array.shape[0] // 2]
else:
    display_image = img_array
```

### 3. Catch exceptions
```python
try:
    # Your visualization code
    visualizer.show_overlay_with_legend(...)
except Exception as e:
    st.error(f"L·ªói khi hi·ªÉn th·ªã: {e}")
    st.image(image, caption="·∫¢nh g·ªëc (fallback)")
```

### 4. Progress indicators cho report generation
```python
with st.spinner("ƒêang t·∫°o b√°o c√°o..."):
    report_bytes = ReportBuilder.create_interpretation_report(...)
```

---

## üìö References

- `utils/interpretation.py` - Main library
- `pages/6_Interpretation_Report.py` - Example usage
- `UX_IMPROVEMENTS_GUIDE.md` - General UX guidelines

---

## üéâ K·∫øt qu·∫£ mong ƒë·ª£i

Sau khi t√≠ch h·ª£p xong:

‚úÖ Ng∆∞·ªùi d√πng th·∫•y **gi·∫£i th√≠ch r√µ r√†ng** cho m·ªçi k·∫øt qu·∫£
‚úÖ **Metrics ƒë∆∞·ª£c di·ªÖn gi·∫£i** b·∫±ng ng√¥n ng·ªØ d·ªÖ hi·ªÉu
‚úÖ **B√°o c√°o PDF/HTML** chuy√™n nghi·ªáp, ƒë·∫ßy ƒë·ªß
‚úÖ **Tr·ª±c quan h√≥a** gi√∫p "nh√¨n l√† hi·ªÉu"
‚úÖ Ph√π h·ª£p cho **ng∆∞·ªùi kh√¥ng chuy√™n y h·ªçc**

---

**Next step:** B·∫Øt ƒë·∫ßu t√≠ch h·ª£p v√†o Preprocessing page (ƒë∆°n gi·∫£n nh·∫•t) r·ªìi lan sang c√°c trang kh√°c! üöÄ
