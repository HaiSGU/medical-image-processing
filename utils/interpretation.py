"""
üß† Medical Image Interpretation Components
===========================================

C√°c c√¥ng c·ª• ƒë·ªÉ gi·∫£i th√≠ch k·∫øt qu·∫£ x·ª≠ l√Ω ·∫£nh y khoa cho ng∆∞·ªùi kh√¥ng chuy√™n.

Components:
- ResultVisualizer: Tr·ª±c quan h√≥a k·∫øt qu·∫£ v·ªõi so s√°nh, overlay, 3D
- MetricsExplainer: Gi·∫£i th√≠ch c√°c ch·ªâ s·ªë k·ªπ thu·∫≠t b·∫±ng ng√¥n ng·ªØ ƒë∆°n gi·∫£n
- InterpretationGenerator: T·∫°o b√°o c√°o gi·∫£i th√≠ch t·ª± ƒë·ªông
- ReportBuilder: T·∫°o b√°o c√°o PDF/HTML ƒë·∫ßy ƒë·ªß

Author: Medical Image Processing Team
"""

import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from matplotlib import cm
from PIL import Image
import io
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime


class ResultVisualizer:
    """Tr·ª±c quan h√≥a k·∫øt qu·∫£ x·ª≠ l√Ω ·∫£nh y khoa"""

    @staticmethod
    def compare_images(
        img_before: np.ndarray,
        img_after: np.ndarray,
        title_before: str = "·∫¢nh g·ªëc",
        title_after: str = "·∫¢nh ƒë√£ x·ª≠ l√Ω",
        description: str = "",
    ):
        """
        So s√°nh 2 ·∫£nh tr∆∞·ªõc v√† sau x·ª≠ l√Ω

        Args:
            img_before: ·∫¢nh tr∆∞·ªõc x·ª≠ l√Ω
            img_after: ·∫¢nh sau x·ª≠ l√Ω
            title_before: Ti√™u ƒë·ªÅ ·∫£nh tr∆∞·ªõc
            title_after: Ti√™u ƒë·ªÅ ·∫£nh sau
            description: M√¥ t·∫£ gi·∫£i th√≠ch
        """
        col1, col2 = st.columns(2)

        with col1:
            st.image(img_before, caption=title_before, use_container_width=True)

        with col2:
            st.image(img_after, caption=title_after, use_container_width=True)

        if description:
            st.info(f"**Gi·∫£i th√≠ch:** {description}")

    @staticmethod
    def overlay_segmentation(
        image: np.ndarray,
        mask: np.ndarray,
        alpha: float = 0.4,
        colormap: str = "jet",
        labels: Optional[Dict[int, str]] = None,
    ) -> np.ndarray:
        """
        T·∫°o overlay c·ªßa mask ph√¢n ƒëo·∫°n l√™n ·∫£nh g·ªëc

        Args:
            image: ·∫¢nh g·ªëc (grayscale ho·∫∑c RGB)
            mask: Mask ph√¢n ƒëo·∫°n (0 = background, >0 = regions)
            alpha: ƒê·ªô trong su·ªët (0-1)
            colormap: B·∫£ng m√†u ('jet', 'hot', 'rainbow')
            labels: Dict mapping mask values to labels

        Returns:
            ·∫¢nh ƒë√£ overlay
        """
        # Chu·∫©n h√≥a ·∫£nh v·ªÅ 0-1
        if image.max() > 1:
            image = image.astype(float) / image.max()

        # Chuy·ªÉn grayscale th√†nh RGB
        if len(image.shape) == 2:
            image_rgb = np.stack([image] * 3, axis=-1)
        else:
            image_rgb = image.copy()

        # T·∫°o colormap cho mask
        cmap = cm.get_cmap(colormap)

        # Normalize mask
        if mask.max() > 0:
            mask_norm = mask.astype(float) / mask.max()
        else:
            mask_norm = mask.astype(float)

        # Apply colormap
        mask_colored = cmap(mask_norm)[..., :3]

        # Blend
        overlay = image_rgb.copy()
        mask_region = mask > 0
        overlay[mask_region] = (
            alpha * mask_colored[mask_region] + (1 - alpha) * image_rgb[mask_region]
        )

        return overlay

    @staticmethod
    def show_overlay_with_legend(
        image: np.ndarray,
        mask: np.ndarray,
        labels: Dict[int, str],
        title: str = "K·∫øt qu·∫£ ph√¢n ƒëo·∫°n",
    ):
        """
        Hi·ªÉn th·ªã overlay v·ªõi ch√∫ th√≠ch ƒë·∫ßy ƒë·ªß

        Args:
            image: ·∫¢nh g·ªëc
            mask: Mask ph√¢n ƒëo·∫°n
            labels: {value: description} - v√≠ d·ª• {1: "Kh·ªëi u", 2: "M√¥ b√¨nh th∆∞·ªùng"}
            title: Ti√™u ƒë·ªÅ
        """
        st.subheader(title)

        # T·∫°o overlay
        overlay = ResultVisualizer.overlay_segmentation(image, mask)

        col1, col2 = st.columns([3, 1])

        with col1:
            st.image(overlay, use_container_width=True)

        with col2:
            st.markdown("**üìç Ch√∫ th√≠ch:**")

            # T√≠nh % di·ªán t√≠ch c·ªßa m·ªói v√πng
            total_pixels = mask.size

            for value, label in labels.items():
                if value == 0:
                    continue

                region_pixels = np.sum(mask == value)
                percentage = (region_pixels / total_pixels) * 100

                # Color indicator
                cmap = cm.get_cmap("jet")
                color_rgb = cmap(value / max(labels.keys()))[:3]
                color_hex = "#{:02x}{:02x}{:02x}".format(
                    int(color_rgb[0] * 255),
                    int(color_rgb[1] * 255),
                    int(color_rgb[2] * 255),
                )

                st.markdown(
                    f'<div style="display: flex; align-items: center; margin-bottom: 10px;">'
                    f'<div style="width: 20px; height: 20px; background-color: {color_hex}; '
                    f'margin-right: 10px; border: 1px solid #ccc;"></div>'
                    f"<div><b>{label}</b><br/><small>{percentage:.1f}% di·ªán t√≠ch</small></div>"
                    f"</div>",
                    unsafe_allow_html=True,
                )

    @staticmethod
    def show_3d_slices(
        volume: np.ndarray,
        axis: int = 2,
        num_slices: int = 9,
        title: str = "C√°c l√°t c·∫Øt 3D",
    ):
        """
        Hi·ªÉn th·ªã nhi·ªÅu slices c·ªßa volume 3D

        Args:
            volume: Volume 3D (depth, height, width) ho·∫∑c (height, width, depth)
            axis: Tr·ª•c ƒë·ªÉ c·∫Øt (0, 1, ho·∫∑c 2)
            num_slices: S·ªë l∆∞·ª£ng slices hi·ªÉn th·ªã
            title: Ti√™u ƒë·ªÅ
        """
        st.subheader(title)

        # Ch·ªçn slices ƒë·ªÅu nhau
        slice_indices = np.linspace(0, volume.shape[axis] - 1, num_slices, dtype=int)

        # T·∫°o grid
        cols = st.columns(3)

        for idx, slice_idx in enumerate(slice_indices):
            # L·∫•y slice
            if axis == 0:
                slice_img = volume[slice_idx, :, :]
            elif axis == 1:
                slice_img = volume[:, slice_idx, :]
            else:
                slice_img = volume[:, :, slice_idx]

            # Hi·ªÉn th·ªã
            col_idx = idx % 3
            with cols[col_idx]:
                st.image(
                    slice_img,
                    caption=f"Slice {slice_idx + 1}",
                    use_container_width=True,
                )


class MetricsExplainer:
    """Gi·∫£i th√≠ch c√°c ch·ªâ s·ªë k·ªπ thu·∫≠t b·∫±ng ng√¥n ng·ªØ ƒë∆°n gi·∫£n"""

    # Dictionary √°nh x·∫° metrics -> gi·∫£i th√≠ch
    EXPLANATIONS = {
        "PSNR": {
            "name": "ƒê·ªô r√µ n√©t (PSNR)",
            "unit": "dB",
            "good_threshold": 30,
            "description": "ƒêo m·ª©c ƒë·ªô nhi·ªÖu trong ·∫£nh. C√†ng cao c√†ng t·ªët.",
            "interpretation": {
                "excellent": "> 40 dB: Ch·∫•t l∆∞·ª£ng xu·∫•t s·∫Øc",
                "good": "30-40 dB: Ch·∫•t l∆∞·ª£ng t·ªët",
                "fair": "20-30 dB: Ch·∫•t l∆∞·ª£ng ch·∫•p nh·∫≠n ƒë∆∞·ª£c",
                "poor": "< 20 dB: Ch·∫•t l∆∞·ª£ng k√©m",
            },
        },
        "SSIM": {
            "name": "ƒê·ªô t∆∞∆°ng ƒë·ªìng c·∫•u tr√∫c (SSIM)",
            "unit": "",
            "good_threshold": 0.9,
            "description": "ƒêo m·ª©c ƒë·ªô gi·ªëng nhau gi·ªØa ·∫£nh g·ªëc v√† ·∫£nh x·ª≠ l√Ω (0-1).",
            "interpretation": {
                "excellent": "> 0.95: R·∫•t gi·ªëng ·∫£nh g·ªëc",
                "good": "0.90-0.95: Gi·ªëng ·∫£nh g·ªëc",
                "fair": "0.80-0.90: T∆∞∆°ng ƒë·ªëi gi·ªëng",
                "poor": "< 0.80: Kh√°c bi·ªát ƒë√°ng k·ªÉ",
            },
        },
        "Dice": {
            "name": "ƒê·ªô ch√≠nh x√°c ph√¢n ƒëo·∫°n (Dice)",
            "unit": "",
            "good_threshold": 0.8,
            "description": "ƒêo m·ª©c ƒë·ªô tr√πng kh·ªõp gi·ªØa v√πng ph√¢n ƒëo·∫°n v√† v√πng th·ª±c t·∫ø (0-1).",
            "interpretation": {
                "excellent": "> 0.90: Ph√¢n ƒëo·∫°n r·∫•t ch√≠nh x√°c",
                "good": "0.80-0.90: Ph√¢n ƒëo·∫°n t·ªët",
                "fair": "0.70-0.80: Ph√¢n ƒëo·∫°n ch·∫•p nh·∫≠n ƒë∆∞·ª£c",
                "poor": "< 0.70: Ph√¢n ƒëo·∫°n k√©m",
            },
        },
        "IoU": {
            "name": "ƒê·ªô tr√πng kh·ªõp (IoU)",
            "unit": "",
            "good_threshold": 0.7,
            "description": "ƒêo ph·∫ßn giao v√† h·ª£p c·ªßa 2 v√πng (0-1).",
            "interpretation": {
                "excellent": "> 0.80: Tr√πng kh·ªõp r·∫•t t·ªët",
                "good": "0.70-0.80: Tr√πng kh·ªõp t·ªët",
                "fair": "0.50-0.70: Tr√πng kh·ªõp ch·∫•p nh·∫≠n ƒë∆∞·ª£c",
                "poor": "< 0.50: Tr√πng kh·ªõp k√©m",
            },
        },
        "MSE": {
            "name": "Sai s·ªë b√¨nh ph∆∞∆°ng trung b√¨nh (MSE)",
            "unit": "",
            "good_threshold": 100,
            "description": "ƒêo s·ª± kh√°c bi·ªát gi·ªØa 2 ·∫£nh. C√†ng th·∫•p c√†ng t·ªët.",
            "interpretation": {
                "excellent": "< 50: Sai s·ªë r·∫•t nh·ªè",
                "good": "50-100: Sai s·ªë nh·ªè",
                "fair": "100-500: Sai s·ªë trung b√¨nh",
                "poor": "> 500: Sai s·ªë l·ªõn",
            },
        },
        "SNR": {
            "name": "T·ª∑ l·ªá t√≠n hi·ªáu/nhi·ªÖu (SNR)",
            "unit": "dB",
            "good_threshold": 20,
            "description": "ƒêo m·ª©c ƒë·ªô t√≠n hi·ªáu so v·ªõi nhi·ªÖu. C√†ng cao c√†ng t·ªët.",
            "interpretation": {
                "excellent": "> 30 dB: T√≠n hi·ªáu r·∫•t m·∫°nh",
                "good": "20-30 dB: T√≠n hi·ªáu t·ªët",
                "fair": "10-20 dB: T√≠n hi·ªáu trung b√¨nh",
                "poor": "< 10 dB: Nhi·ªÖu cao",
            },
        },
    }

    @staticmethod
    def explain_metric(metric_name: str, value: float) -> Dict[str, Any]:
        """
        Gi·∫£i th√≠ch √Ω nghƒ©a c·ªßa m·ªôt metric

        Args:
            metric_name: T√™n metric ('PSNR', 'SSIM', etc.)
            value: Gi√° tr·ªã c·ªßa metric

        Returns:
            Dict ch·ª©a t√™n, gi√° tr·ªã, ƒë√°nh gi√°, m√¥ t·∫£
        """
        if metric_name not in MetricsExplainer.EXPLANATIONS:
            return {
                "name": metric_name,
                "value": value,
                "assessment": "unknown",
                "description": "Ch·ªâ s·ªë k·ªπ thu·∫≠t",
            }

        info = MetricsExplainer.EXPLANATIONS[metric_name]

        # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng
        if metric_name in ["PSNR", "SSIM", "Dice", "IoU", "SNR"]:
            # C√†ng cao c√†ng t·ªët
            if metric_name == "PSNR" or metric_name == "SNR":
                if value > 40:
                    assessment = "excellent"
                elif value > 30:
                    assessment = "good"
                elif value > 20:
                    assessment = "fair"
                else:
                    assessment = "poor"
            else:  # SSIM, Dice, IoU
                if value > 0.9:
                    assessment = "excellent"
                elif value > 0.8:
                    assessment = "good"
                elif value > 0.7:
                    assessment = "fair"
                else:
                    assessment = "poor"
        else:  # MSE
            # C√†ng th·∫•p c√†ng t·ªët
            if value < 50:
                assessment = "excellent"
            elif value < 100:
                assessment = "good"
            elif value < 500:
                assessment = "fair"
            else:
                assessment = "poor"

        return {
            "name": info["name"],
            "value": value,
            "unit": info["unit"],
            "assessment": assessment,
            "description": info["description"],
            "interpretation": info["interpretation"][assessment],
        }

    @staticmethod
    def show_metrics_dashboard(
        metrics: Dict[str, float], title: str = "Ch·ªâ s·ªë ch·∫•t l∆∞·ª£ng"
    ):
        """
        Hi·ªÉn th·ªã dashboard c√°c metrics v·ªõi gi·∫£i th√≠ch

        Args:
            metrics: Dict {metric_name: value}
            title: Ti√™u ƒë·ªÅ dashboard
        """
        st.subheader(title)

        # T·∫°o columns cho metrics
        num_metrics = len(metrics)
        cols = st.columns(min(num_metrics, 4))

        for idx, (metric_name, value) in enumerate(metrics.items()):
            col_idx = idx % 4

            with cols[col_idx]:
                explanation = MetricsExplainer.explain_metric(metric_name, value)

                # Color based on assessment
                color_map = {
                    "excellent": "üü¢",
                    "good": "üü°",
                    "fair": "üü†",
                    "poor": "üî¥",
                    "unknown": "‚ö™",
                }

                icon = color_map.get(explanation["assessment"], "‚ö™")

                # Format value
                if explanation["unit"]:
                    value_str = f"{value:.2f} {explanation['unit']}"
                else:
                    value_str = f"{value:.3f}"

                st.metric(label=f"{icon} {explanation['name']}", value=value_str)

                with st.expander("‚ÑπÔ∏è Gi·∫£i th√≠ch"):
                    st.markdown(f"**√ù nghƒ©a:** {explanation['description']}")
                    st.markdown(f"**ƒê√°nh gi√°:** {explanation['interpretation']}")


class InterpretationGenerator:
    """T·∫°o b√°o c√°o gi·∫£i th√≠ch t·ª± ƒë·ªông t·ª´ k·∫øt qu·∫£ x·ª≠ l√Ω"""

    @staticmethod
    def generate_interpretation(
        task_type: str,
        metrics: Dict[str, float],
        image_info: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        T·∫°o ƒëo·∫°n gi·∫£i th√≠ch t·ª± ƒë·ªông cho k·∫øt qu·∫£

        Args:
            task_type: Lo·∫°i task ('anonymization', 'segmentation', 'reconstruction', 'preprocessing')
            metrics: Dict c√°c metrics
            image_info: Th√¥ng tin b·ªï sung v·ªÅ ·∫£nh

        Returns:
            ƒêo·∫°n text gi·∫£i th√≠ch
        """
        if task_type == "anonymization":
            return InterpretationGenerator._interpret_anonymization(metrics, image_info)
        elif task_type == "segmentation":
            return InterpretationGenerator._interpret_segmentation(metrics, image_info)
        elif task_type == "reconstruction":
            return InterpretationGenerator._interpret_reconstruction(
                metrics, image_info
            )
        elif task_type == "preprocessing":
            return InterpretationGenerator._interpret_preprocessing(metrics, image_info)
        else:
            return "K·∫øt qu·∫£ x·ª≠ l√Ω ·∫£nh ƒë√£ ho√†n t·∫•t."

    @staticmethod
    def _interpret_anonymization(metrics: Dict, info: Optional[Dict]) -> str:
        """Gi·∫£i th√≠ch k·∫øt qu·∫£ anonymization"""
        text = "### K·∫øt qu·∫£ ·∫®n danh h√≥a DICOM\n\n"
        text += "**Ho√†n t·∫•t:** T·∫•t c·∫£ th√¥ng tin nh·∫≠n d·∫°ng c√° nh√¢n ƒë√£ ƒë∆∞·ª£c x√≥a kh·ªèi ·∫£nh y t·∫ø.\n\n"

        if info and "fields_removed" in info:
            text += f"**C√°c tr∆∞·ªùng ƒë√£ x√≥a:** {', '.join(info['fields_removed'])}\n\n"

        text += "**√ù nghƒ©a:** ·∫¢nh n√†y gi·ªù ƒë√¢y an to√†n ƒë·ªÉ chia s·∫ª cho m·ª•c ƒë√≠ch nghi√™n c·ª©u ho·∫∑c gi·∫£ng d·∫°y "
        text += "m√† kh√¥ng vi ph·∫°m quy·ªÅn ri√™ng t∆∞ c·ªßa b·ªánh nh√¢n.\n\n"
        text += "**L∆∞u √Ω:** Lu√¥n ki·ªÉm tra k·ªπ tr∆∞·ªõc khi chia s·∫ª d·ªØ li·ªáu y t·∫ø."

        return text

    @staticmethod
    def _interpret_segmentation(metrics: Dict, info: Optional[Dict]) -> str:
        """Gi·∫£i th√≠ch k·∫øt qu·∫£ segmentation"""
        text = "### K·∫øt qu·∫£ Ph√¢n ƒëo·∫°n ·∫£nh y t·∫ø\n\n"

        if "Dice" in metrics:
            dice = metrics["Dice"]
            if dice > 0.9:
                quality = "xu·∫•t s·∫Øc"
            elif dice > 0.8:
                quality = "t·ªët"
            elif dice > 0.7:
                quality = "ch·∫•p nh·∫≠n ƒë∆∞·ª£c"
            else:
                quality = "c·∫ßn c·∫£i thi·ªán"

            text += (
                f"**ƒê·ªô ch√≠nh x√°c:** {dice:.3f} - Ch·∫•t l∆∞·ª£ng ph√¢n ƒëo·∫°n {quality}.\n\n"
            )

        if info and "region_percentage" in info:
            pct = info["region_percentage"]
            text += f"**V√πng ph√°t hi·ªán:** Chi·∫øm {pct:.1f}% t·ªïng th·ªÉ t√≠ch ·∫£nh.\n\n"

        text += "**√ù nghƒ©a:** H·ªá th·ªëng ƒë√£ t·ª± ƒë·ªông x√°c ƒë·ªãnh v√† t√°ch v√πng quan t√¢m "
        text += (
            "(v√≠ d·ª•: kh·ªëi u, m√¥ n√£o) kh·ªèi n·ªÅn. V√πng ƒë∆∞·ª£c t√¥ m√†u gi√∫p b√°c sƒ© d·ªÖ d√†ng "
        )
        text += "x√°c ƒë·ªãnh v·ªã tr√≠ v√† k√≠ch th∆∞·ªõc b·∫•t th∆∞·ªùng.\n\n"
        text += "**L∆∞u √Ω:** ƒê√¢y ch·ªâ l√† c√¥ng c·ª• h·ªó tr·ª£, kh√¥ng thay th·∫ø ch·∫©n ƒëo√°n y khoa."

        return text

    @staticmethod
    def _interpret_reconstruction(metrics: Dict, info: Optional[Dict]) -> str:
        """Gi·∫£i th√≠ch k·∫øt qu·∫£ reconstruction"""
        text = "### K·∫øt qu·∫£ T√°i t·∫°o ·∫£nh\n\n"

        if "PSNR" in metrics:
            psnr = metrics["PSNR"]
            if psnr > 35:
                quality = "r·∫•t cao"
            elif psnr > 30:
                quality = "cao"
            elif psnr > 25:
                quality = "trung b√¨nh"
            else:
                quality = "th·∫•p"

            text += f"**Ch·∫•t l∆∞·ª£ng t√°i t·∫°o:** PSNR = {psnr:.2f} dB - Ch·∫•t l∆∞·ª£ng {quality}.\n\n"

        if "SSIM" in metrics:
            ssim = metrics["SSIM"]
            text += f"**ƒê·ªô t∆∞∆°ng ƒë·ªìng:** SSIM = {ssim:.3f} - "
            text += f"·∫¢nh t√°i t·∫°o {'r·∫•t gi·ªëng' if ssim > 0.95 else 't∆∞∆°ng ƒë·ªëi gi·ªëng'} ·∫£nh g·ªëc.\n\n"

        text += (
            "**√ù nghƒ©a:** T·ª´ d·ªØ li·ªáu th√¥ c·ªßa m√°y qu√©t (CT/MRI), h·ªá th·ªëng ƒë√£ t√°i t·∫°o "
        )
        text += (
            "th√†nh h√¨nh ·∫£nh c√≥ th·ªÉ nh√¨n th·∫•y ƒë∆∞·ª£c. Ch·∫•t l∆∞·ª£ng t·ªët gi√∫p b√°c sƒ© quan s√°t "
        )
        text += "r√µ c√°c chi ti·∫øt m√¥, x∆∞∆°ng, c∆° quan n·ªôi t·∫°ng.\n\n"

        if info and "method" in info:
            text += f"**Ph∆∞∆°ng ph√°p:** {info['method']}\n\n"

        text += "**L∆∞u √Ω:** C√°c th√¥ng s·ªë k·ªπ thu·∫≠t (g√≥c qu√©t, ƒë·ªô ph√¢n gi·∫£i) ·∫£nh h∆∞·ªüng ƒë·∫øn ch·∫•t l∆∞·ª£ng."

        return text

    @staticmethod
    def _interpret_preprocessing(metrics: Dict, info: Optional[Dict]) -> str:
        """Gi·∫£i th√≠ch k·∫øt qu·∫£ preprocessing"""
        text = "### K·∫øt qu·∫£ Ti·ªÅn x·ª≠ l√Ω ·∫£nh\n\n"

        operations = info.get("operations", []) if info else []

        if operations:
            text += "**C√°c b∆∞·ªõc ƒë√£ th·ª±c hi·ªán:**\n"
            for op in operations:
                if op == "normalize":
                    text += "- Chu·∫©n h√≥a ƒë·ªô s√°ng (gi√∫p ·∫£nh ƒë·ªìng ƒë·ªÅu)\n"
                elif op == "denoise":
                    text += "- Gi·∫£m nhi·ªÖu (l√†m r√µ ·∫£nh)\n"
                elif op == "enhance":
                    text += "- TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n (n·ªïi b·∫≠t chi ti·∫øt)\n"
                elif op == "resize":
                    text += "- Thay ƒë·ªïi k√≠ch th∆∞·ªõc\n"
            text += "\n"

        if "PSNR" in metrics:
            psnr = metrics["PSNR"]
            text += f"**Ch·∫•t l∆∞·ª£ng:** PSNR = {psnr:.2f} dB\n\n"

        text += "**√ù nghƒ©a:** ·∫¢nh ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch v√† t·ªëi ∆∞u ƒë·ªÉ ph·ª•c v·ª• c√°c b∆∞·ªõc ph√¢n t√≠ch ti·∫øp theo. "
        text += "C√°c m√¥, kh·ªëi u, hay b·∫•t th∆∞·ªùng s·∫Ω n·ªïi b·∫≠t r√µ r√†ng h∆°n.\n\n"
        text += (
            "**L∆∞u √Ω:** Ti·ªÅn x·ª≠ l√Ω gi√∫p c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c c·ªßa c√°c thu·∫≠t to√°n AI."
        )

        return text


class ReportBuilder:
    """T·∫°o b√°o c√°o PDF/HTML ƒë·∫ßy ƒë·ªß v·ªõi gi·∫£i th√≠ch"""

    @staticmethod
    def create_interpretation_report(
        title: str,
        task_type: str,
        images: Dict[str, np.ndarray],
        metrics: Dict[str, float],
        interpretation: str,
        output_format: str = "pdf",
    ) -> bytes:
        """
        T·∫°o b√°o c√°o gi·∫£i th√≠ch ƒë·∫ßy ƒë·ªß

        Args:
            title: Ti√™u ƒë·ªÅ b√°o c√°o
            task_type: Lo·∫°i task
            images: Dict {name: image_array}
            metrics: Dict {metric_name: value}
            interpretation: ƒêo·∫°n gi·∫£i th√≠ch
            output_format: 'pdf' ho·∫∑c 'html'

        Returns:
            Bytes c·ªßa file b√°o c√°o
        """
        if output_format == "pdf":
            return ReportBuilder._create_pdf_report(
                title, task_type, images, metrics, interpretation
            )
        else:
            return ReportBuilder._create_html_report(
                title, task_type, images, metrics, interpretation
            )

    @staticmethod
    def _create_pdf_report(
        title: str,
        task_type: str,
        images: Dict[str, np.ndarray],
        metrics: Dict[str, float],
        interpretation: str,
    ) -> bytes:
        """T·∫°o PDF report"""
        from reportlab.lib.pagesizes import letter, A4
        from reportlab.platypus import (
            SimpleDocTemplate,
            Paragraph,
            Spacer,
            Image as RLImage,
            Table,
        )
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch
        from reportlab.lib import colors

        buffer = io.BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        story = []
        styles = getSampleStyleSheet()

        # Title
        title_style = ParagraphStyle(
            "CustomTitle",
            parent=styles["Heading1"],
            fontSize=24,
            textColor=colors.HexColor("#1f77b4"),
            spaceAfter=30,
        )
        story.append(Paragraph(title, title_style))
        story.append(Spacer(1, 0.2 * inch))

        # Timestamp
        timestamp = datetime.now().strftime("%d/%m/%Y %H:%M:%S")
        story.append(Paragraph(f"<b>Th·ªùi gian:</b> {timestamp}", styles["Normal"]))
        story.append(
            Paragraph(f"<b>Lo·∫°i x·ª≠ l√Ω:</b> {task_type.capitalize()}", styles["Normal"])
        )
        story.append(Spacer(1, 0.3 * inch))

        # Metrics table
        if metrics:
            story.append(Paragraph("<b>Ch·ªâ s·ªë k·ªπ thu·∫≠t:</b>", styles["Heading2"]))

            table_data = [["Ch·ªâ s·ªë", "Gi√° tr·ªã", "ƒê√°nh gi√°"]]

            for metric_name, value in metrics.items():
                explanation = MetricsExplainer.explain_metric(metric_name, value)

                assessment_map = {
                    "excellent": "Xu·∫•t s·∫Øc",
                    "good": "T·ªët",
                    "fair": "Ch·∫•p nh·∫≠n ƒë∆∞·ª£c",
                    "poor": "K√©m",
                }

                if explanation["unit"]:
                    value_str = f"{value:.2f} {explanation['unit']}"
                else:
                    value_str = f"{value:.3f}"

                table_data.append(
                    [
                        explanation["name"],
                        value_str,
                        assessment_map.get(explanation["assessment"], "-"),
                    ]
                )

            table = Table(table_data)
            table.setStyle(
                [
                    ("BACKGROUND", (0, 0), (-1, 0), colors.grey),
                    ("TEXTCOLOR", (0, 0), (-1, 0), colors.whitesmoke),
                    ("ALIGN", (0, 0), (-1, -1), "CENTER"),
                    ("FONTNAME", (0, 0), (-1, 0), "Helvetica-Bold"),
                    ("FONTSIZE", (0, 0), (-1, 0), 12),
                    ("BOTTOMPADDING", (0, 0), (-1, 0), 12),
                    ("BACKGROUND", (0, 1), (-1, -1), colors.beige),
                    ("GRID", (0, 0), (-1, -1), 1, colors.black),
                ]
            )

            story.append(table)
            story.append(Spacer(1, 0.3 * inch))

        # Interpretation
        story.append(Paragraph("<b>Gi·∫£i th√≠ch k·∫øt qu·∫£:</b>", styles["Heading2"]))

        # Clean markdown formatting
        interp_clean = interpretation.replace("###", "").replace("**", "")
        for line in interp_clean.split("\n"):
            if line.strip():
                story.append(Paragraph(line, styles["Normal"]))

        story.append(Spacer(1, 0.3 * inch))

        # Images
        if images:
            story.append(Paragraph("<b>H√¨nh ·∫£nh:</b>", styles["Heading2"]))

            for img_name, img_array in images.items():
                # Convert to PIL Image
                if img_array.max() > 1:
                    img_array = (img_array / img_array.max() * 255).astype(np.uint8)
                else:
                    img_array = (img_array * 255).astype(np.uint8)

                pil_img = Image.fromarray(img_array)

                # Save to buffer
                img_buffer = io.BytesIO()
                pil_img.save(img_buffer, format="PNG")
                img_buffer.seek(0)

                # Add to PDF
                rl_img = RLImage(img_buffer, width=4 * inch, height=3 * inch)
                story.append(Paragraph(img_name, styles["Normal"]))
                story.append(rl_img)
                story.append(Spacer(1, 0.2 * inch))

        # Disclaimer
        story.append(Spacer(1, 0.5 * inch))
        disclaimer_style = ParagraphStyle(
            "Disclaimer",
            parent=styles["Normal"],
            fontSize=10,
            textColor=colors.red,
            leftIndent=20,
            rightIndent=20,
        )
        story.append(
            Paragraph(
                "<b>L∆∞u √Ω:</b> B√°o c√°o n√†y ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o k·ªπ thu·∫≠t. "
                "Kh√¥ng thay th·∫ø cho √Ω ki·∫øn ch·∫©n ƒëo√°n c·ªßa b√°c sƒ© chuy√™n khoa.",
                disclaimer_style,
            )
        )

        doc.build(story)
        buffer.seek(0)
        return buffer.read()

    @staticmethod
    def _create_html_report(
        title: str,
        task_type: str,
        images: Dict[str, np.ndarray],
        metrics: Dict[str, float],
        interpretation: str,
    ) -> bytes:
        """T·∫°o HTML report"""
        html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="UTF-8">
            <title>{title}</title>
            <style>
                body {{
                    font-family: Arial, sans-serif;
                    max-width: 1200px;
                    margin: 0 auto;
                    padding: 20px;
                    background-color: #f5f5f5;
                }}
                .header {{
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    color: white;
                    padding: 30px;
                    border-radius: 10px;
                    margin-bottom: 30px;
                }}
                .header h1 {{
                    margin: 0;
                    font-size: 2em;
                }}
                .section {{
                    background: white;
                    padding: 20px;
                    margin-bottom: 20px;
                    border-radius: 8px;
                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
                }}
                .metrics-grid {{
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                    gap: 15px;
                    margin-top: 15px;
                }}
                .metric-card {{
                    background: #f8f9fa;
                    padding: 15px;
                    border-radius: 8px;
                    border-left: 4px solid #667eea;
                }}
                .metric-card .value {{
                    font-size: 1.5em;
                    font-weight: bold;
                    color: #667eea;
                }}
                .images-grid {{
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
                    gap: 20px;
                    margin-top: 15px;
                }}
                .image-card {{
                    text-align: center;
                }}
                .image-card img {{
                    max-width: 100%;
                    border-radius: 8px;
                    box-shadow: 0 2px 8px rgba(0,0,0,0.1);
                }}
                .disclaimer {{
                    background: #fff3cd;
                    border-left: 4px solid #ffc107;
                    padding: 15px;
                    margin-top: 30px;
                    border-radius: 5px;
                }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>{title}</h1>
                <p>Lo·∫°i x·ª≠ l√Ω: {task_type.capitalize()}</p>
                <p>Th·ªùi gian: {datetime.now().strftime("%d/%m/%Y %H:%M:%S")}</p>
            </div>
        """

        # Metrics
        if metrics:
            html += '<div class="section"><h2>Ch·ªâ s·ªë k·ªπ thu·∫≠t</h2><div class="metrics-grid">'

            for metric_name, value in metrics.items():
                explanation = MetricsExplainer.explain_metric(metric_name, value)

                if explanation["unit"]:
                    value_str = f"{value:.2f} {explanation['unit']}"
                else:
                    value_str = f"{value:.3f}"

                html += f"""
                <div class="metric-card">
                    <div><strong>{explanation['name']}</strong></div>
                    <div class="value">{value_str}</div>
                    <div><small>{explanation['interpretation']}</small></div>
                </div>
                """

            html += "</div></div>"

        # Interpretation
        html += (
            f'<div class="section"><h2>Gi·∫£i th√≠ch k·∫øt qu·∫£</h2>{interpretation}</div>'
        )

        # Images
        if images:
            html += '<div class="section"><h2>üñºÔ∏è H√¨nh ·∫£nh</h2><div class="images-grid">'

            for img_name, img_array in images.items():
                # Convert to base64
                if img_array.max() > 1:
                    img_array = (img_array / img_array.max() * 255).astype(np.uint8)
                else:
                    img_array = (img_array * 255).astype(np.uint8)

                pil_img = Image.fromarray(img_array)
                img_buffer = io.BytesIO()
                pil_img.save(img_buffer, format="PNG")
                img_buffer.seek(0)

                import base64

                img_base64 = base64.b64encode(img_buffer.read()).decode()

                html += f"""
                <div class="image-card">
                    <img src="data:image/png;base64,{img_base64}" alt="{img_name}">
                    <p><strong>{img_name}</strong></p>
                </div>
                """

            html += "</div></div>"

        # Disclaimer
        html += """
        <div class="disclaimer">
            <strong>L∆∞u √Ω:</strong> B√°o c√°o n√†y ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o k·ªπ thu·∫≠t.
            Kh√¥ng thay th·∫ø cho √Ω ki·∫øn ch·∫©n ƒëo√°n c·ªßa b√°c sƒ© chuy√™n khoa.
        </div>
        </body>
        </html>
        """

        return html.encode("utf-8")


# Helper functions
def show_interpretation_section(
    task_type: str,
    metrics: Dict[str, float],
    image_info: Optional[Dict[str, Any]] = None,
):
    """
    Hi·ªÉn th·ªã section gi·∫£i th√≠ch trong Streamlit

    Args:
        task_type: Lo·∫°i task
        metrics: Metrics
        image_info: Th√¥ng tin b·ªï sung
    """
    st.markdown("---")
    st.subheader("Gi·∫£i th√≠ch k·∫øt qu·∫£")

    interpretation = InterpretationGenerator.generate_interpretation(
        task_type, metrics, image_info
    )

    st.markdown(interpretation)
