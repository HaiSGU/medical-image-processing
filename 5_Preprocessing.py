"""
Trang Ti·ªÅn x·ª≠ l√Ω ·∫¢nh

√Åp d·ª•ng c√°c ph√©p ti·ªÅn x·ª≠ l√Ω cho ·∫£nh y t·∫ø.

T√°c gi·∫£: HaiSGU
Ng√†y: 2025-10-28
"""

import streamlit as st
import tempfile
from pathlib import Path
import sys
import numpy as np
import matplotlib.pyplot as plt
import io
from skimage import exposure, filters
from scipy import ndimage

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Import from src/ modules
from src.preprocessing.image_transforms import ImageTransforms
from utils.file_io import MedicalImageIO

# Import interpretation components
from utils.interpretation import (
    ResultVisualizer,
    MetricsExplainer,
    show_interpretation_section,
)

# Page config
st.set_page_config(page_title=" Ti·ªÅn x·ª≠ l√Ω ·∫¢nh", layout="wide")

# Initialize session state
if "prep_image" not in st.session_state:
    st.session_state.prep_image = None
if "prep_processed" not in st.session_state:
    st.session_state.prep_processed = None
if "prep_operations" not in st.session_state:
    st.session_state.prep_operations = []

# Header
st.title(" Ti·ªÅn x·ª≠ l√Ω ·∫¢nh")
st.markdown("Bi·∫øn ƒë·ªïi v√† n√¢ng cao ch·∫•t l∆∞·ª£ng ·∫£nh y t·∫ø ƒë·ªÉ ph√¢n t√≠ch")

# Info
with st.expander("About Preprocessing"):
    col1, col2 = st.columns(2)

    with col1:
        st.markdown(
            """
        **Why Preprocessing?**
        
        Raw medical images need preparation:
        - Different intensity ranges
        - Varying sizes
        - Scanner noise
        - Low contrast
        
        **Operations:**
        - Normalization
        - Denoising
        - Resizing
        - Contrast enhancement
        """
        )

    with col2:
        st.markdown(
            """
        **Recommended Order:**
        
        1. **Normalize** intensities first
        2. **Denoise** to remove noise
        3. **Resize** to target size
        4. **Enhance** contrast last
        
        **Tips:**
        - Apply operations one at a time
        - Check preview before download
        - Save pipeline for reuse
        """
        )

st.markdown("---")

# Sidebar
with st.sidebar:
    st.header(" C√°c ph√©p to√°n")

    st.markdown("### C∆∞·ªùng ƒë·ªô")

    normalize_enabled = st.checkbox("Chu·∫©n h√≥a", value=False)
    if normalize_enabled:
        norm_method = st.selectbox(
            "Ph∆∞∆°ng ph√°p:",
            ["Min-Max (0-1)", "Z-Score", "C·∫Øt ph√¢n v·ªã"],
            help="Ph∆∞∆°ng ph√°p chu·∫©n h√≥a",
        )

        if norm_method == "C·∫Øt ph√¢n v·ªã":
            lower_p = st.slider("Ph√¢n v·ªã d∆∞·ªõi", 0, 50, 2)
            upper_p = st.slider("Ph√¢n v·ªã tr√™n", 50, 100, 98)

    enhance_enabled = st.checkbox("TƒÉng c∆∞·ªùng T∆∞∆°ng ph·∫£n", value=False)
    if enhance_enabled:
        enhance_method = st.selectbox(
            "Ph∆∞∆°ng ph√°p:",
            ["C√¢n b·∫±ng Histogram", "CLAHE", "Hi·ªáu ch·ªânh Gamma"],
            help="Ph∆∞∆°ng ph√°p tƒÉng c∆∞·ªùng t∆∞∆°ng ph·∫£n",
        )

        if enhance_method == "CLAHE":
            clip_limit = st.slider("Gi·ªõi h·∫°n c·∫Øt", 0.5, 5.0, 2.0, step=0.5)
        elif enhance_method == "Hi·ªáu ch·ªânh Gamma":
            gamma = st.slider("Gamma", 0.1, 3.0, 1.0, step=0.1)

    st.markdown("---")
    st.markdown("### Kh√¥ng gian")

    resize_enabled = st.checkbox("Thay ƒë·ªïi k√≠ch th∆∞·ªõc", value=False)
    if resize_enabled:
        target_size = st.slider("K√≠ch th∆∞·ªõc ƒë√≠ch", 64, 512, 256, step=64)

    crop_enabled = st.checkbox("C·∫Øt theo N·ªôi dung", value=False)

    st.markdown("---")
    st.markdown("### Kh·ª≠ nhi·ªÖu")

    denoise_enabled = st.checkbox("Kh·ª≠ nhi·ªÖu", value=False)
    if denoise_enabled:
        denoise_method = st.selectbox(
            "Ph∆∞∆°ng ph√°p:", ["Gaussian", "Median"], help="Ph∆∞∆°ng ph√°p kh·ª≠ nhi·ªÖu"
        )

        if denoise_method == "Gaussian":
            sigma = st.slider("Sigma", 0.1, 5.0, 1.0, step=0.1)
        else:
            kernel_size = st.slider("K√≠ch th∆∞·ªõc Kernel", 3, 11, 5, step=2)

    st.markdown("---")
    st.info(" B·∫≠t c√°c ph√©p to√°n theo th·ª© t·ª± khuy·∫øn ngh·ªã")

# Upload
st.subheader(" T·∫£i l√™n ·∫¢nh")

uploaded_file = st.file_uploader(
    "Ch·ªçn file ·∫£nh (.nii, .dcm, .nrrd, .mha, .npy)",
    type=["nii", "gz", "dcm", "nrrd", "mha", "npy"],
    help="T·∫£i l√™n ·∫£nh y t·∫ø ƒë·ªÉ ti·ªÅn x·ª≠ l√Ω",
)

if uploaded_file:
    # Load image
    with tempfile.NamedTemporaryFile(
        delete=False, suffix=Path(uploaded_file.name).suffix
    ) as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_path = tmp_file.name

    try:
        with st.spinner("Loading image..."):
            io_handler = MedicalImageIO()
            image_data, metadata = io_handler.read_image(tmp_path)

            # Use 2D slice if 3D
            if image_data.ndim == 3:
                slice_idx = image_data.shape[2] // 2
                image_2d = image_data[:, :, slice_idx]
                st.info(f"Using middle slice ({slice_idx}) from 3D volume")
            else:
                image_2d = image_data

            st.session_state.prep_image = image_2d

        st.success(f" Loaded: {image_2d.shape}")

        # Show original
        col1, col2, col3 = st.columns(3)
        col1.metric("Shape", f"{image_2d.shape[0]}√ó{image_2d.shape[1]}")
        col2.metric("Range", f"{image_2d.min():.1f} - {image_2d.max():.1f}")
        col3.metric("Mean", f"{image_2d.mean():.1f}")

    except Exception as e:
        st.error(f" Error loading image: {str(e)}")
        st.stop()

    st.markdown("---")

    # Apply preprocessing button
    if st.button(" Apply Preprocessing", type="primary", use_container_width=True):

        with st.spinner("Processing..."):
            try:
                processed = image_2d.copy()
                operations = []
                transformer = ImageTransforms()

                # 1. Normalize
                if normalize_enabled:
                    if norm_method == "Min-Max (0-1)":
                        processed = transformer.normalize_intensity(
                            processed, method="minmax"
                        )
                        operations.append("Normalize (Min-Max)")

                    elif norm_method == "Z-Score":
                        processed = transformer.normalize_intensity(
                            processed, method="zscore"
                        )
                        operations.append("Normalize (Z-Score)")

                    else:  # Percentile Clipping
                        processed = transformer.normalize_intensity(
                            processed,
                            method="percentile",
                            percentile_range=(lower_p, upper_p),
                        )
                        operations.append(f"Normalize (Percentile {lower_p}-{upper_p})")

                # 2. Denoise
                if denoise_enabled:
                    if denoise_method == "Gaussian":
                        processed = filters.gaussian(processed, sigma=sigma)
                        operations.append(f"Gaussian Blur (œÉ={sigma})")
                    else:  # Median
                        processed = filters.median(
                            processed, footprint=np.ones((kernel_size, kernel_size))
                        )
                        operations.append(f"Median Filter (k={kernel_size})")

                # 3. Resize
                if resize_enabled:
                    from skimage.transform import resize

                    processed = resize(
                        processed,
                        (target_size, target_size),
                        anti_aliasing=True,
                        preserve_range=True,
                    )
                    operations.append(f"Resize ({target_size}√ó{target_size})")

                # 4. Crop to content
                if crop_enabled:
                    # Find non-zero bounding box
                    coords = np.argwhere(processed > np.percentile(processed, 5))
                    if len(coords) > 0:
                        y_min, x_min = coords.min(axis=0)
                        y_max, x_max = coords.max(axis=0)
                        processed = processed[y_min : y_max + 1, x_min : x_max + 1]
                        operations.append("Crop to Content")

                # 5. Enhance contrast
                if enhance_enabled:
                    if enhance_method == "Histogram Equalization":
                        processed = exposure.equalize_hist(processed)
                        operations.append("Histogram Equalization")

                    elif enhance_method == "CLAHE":
                        processed = exposure.equalize_adapthist(
                            processed, clip_limit=clip_limit
                        )
                        operations.append(f"CLAHE (clip={clip_limit})")

                    else:  # Gamma
                        processed = exposure.adjust_gamma(processed, gamma)
                        operations.append(f"Gamma Correction (Œ≥={gamma})")

                # Store results
                st.session_state.prep_processed = processed
                st.session_state.prep_operations = operations

                st.success("Preprocessing complete!")

            except Exception as e:
                st.error(f" Error during preprocessing: {str(e)}")
                st.exception(e)

    # Display results
    if st.session_state.prep_processed is not None:
        st.markdown("---")
        st.header("Results")

        original = st.session_state.prep_image
        processed = st.session_state.prep_processed

        # Statistics comparison
        st.subheader("Statistics Comparison")

        col1, col2, col3, col4 = st.columns(4)

        col1.metric(
            "Shape",
            f"{processed.shape[0]}√ó{processed.shape[1]}",
            delta=f"Original: {original.shape[0]}√ó{original.shape[1]}",
        )

        col2.metric(
            "Min Value",
            f"{processed.min():.2f}",
            delta=f"{processed.min() - original.min():.2f}",
        )

        col3.metric(
            "Max Value",
            f"{processed.max():.2f}",
            delta=f"{processed.max() - original.max():.2f}",
        )

        col4.metric(
            "Mean",
            f"{processed.mean():.2f}",
            delta=f"{processed.mean() - original.mean():.2f}",
        )

        # Before/After visualization
        st.markdown("---")
        st.subheader(" Before/After Comparison")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**Original Image**")

            fig, ax = plt.subplots(figsize=(8, 8))
            ax.imshow(original, cmap="gray")
            ax.set_title("Original", fontsize=14, fontweight="bold")
            ax.axis("off")
            st.pyplot(fig)
            plt.close()

            st.caption(
                f"Shape: {original.shape} | "
                f"Range: [{original.min():.1f}, {original.max():.1f}]"
            )

        with col2:
            st.markdown("**Processed Image**")

            fig, ax = plt.subplots(figsize=(8, 8))
            ax.imshow(processed, cmap="gray")
            ax.set_title("Processed", fontsize=14, fontweight="bold")
            ax.axis("off")
            st.pyplot(fig)
            plt.close()

            st.caption(
                f"Shape: {processed.shape} | "
                f"Range: [{processed.min():.1f}, {processed.max():.1f}]"
            )

        # Enhanced Comparison with Interpretation
        st.markdown("---")
        st.subheader("üîç So s√°nh Chi ti·∫øt")

        visualizer = ResultVisualizer()
        visualizer.compare_images(
            original,
            processed,
            title_before="·∫¢nh g·ªëc",
            title_after="·∫¢nh ƒë√£ x·ª≠ l√Ω",
            description="·∫¢nh ƒë√£ ƒë∆∞·ª£c c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng th√¥ng qua c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω. "
            "C√°c chi ti·∫øt m√¥ v√† c·∫•u tr√∫c gi·ªù ƒë√¢y r√µ r√†ng h∆°n, gi√∫p d·ªÖ d√†ng ph√¢n t√≠ch.",
        )

        # Calculate quality metrics
        st.markdown("---")
        st.subheader("üìä Ch·ªâ s·ªë Ch·∫•t l∆∞·ª£ng")

        try:
            from skimage.metrics import peak_signal_noise_ratio, structural_similarity

            # Normalize images to same range for metrics
            orig_norm = (original - original.min()) / (original.max() - original.min())
            proc_norm = (processed - processed.min()) / (
                processed.max() - processed.min()
            )

            # Ensure same size
            if orig_norm.shape != proc_norm.shape:
                from skimage.transform import resize

                proc_norm = resize(proc_norm, orig_norm.shape, anti_aliasing=True)

            psnr = peak_signal_noise_ratio(orig_norm, proc_norm, data_range=1.0)
            ssim = structural_similarity(orig_norm, proc_norm, data_range=1.0)
            mse = np.mean((orig_norm - proc_norm) ** 2)

            metrics = {"PSNR": psnr, "SSIM": ssim, "MSE": mse}

            # Show metrics dashboard
            metrics_explainer = MetricsExplainer()
            metrics_explainer.show_metrics_dashboard(
                metrics, title="ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng sau x·ª≠ l√Ω"
            )

        except Exception as e:
            st.warning(f"Kh√¥ng th·ªÉ t√≠nh metrics: {e}")
            metrics = {}

        # Interpretation section
        show_interpretation_section(
            task_type="preprocessing",
            metrics=metrics,
            image_info={"operations": st.session_state.prep_operations},
        )

        # Histogram comparison
        st.markdown("---")
        st.subheader("üìà Ph√¢n b·ªë C∆∞·ªùng ƒë·ªô")

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))

        # Original histogram
        ax1.hist(original.flatten(), bins=50, color="steelblue", alpha=0.7)
        ax1.set_title("Original Histogram", fontweight="bold")
        ax1.set_xlabel("Intensity")
        ax1.set_ylabel("Frequency")
        ax1.grid(alpha=0.3)

        # Processed histogram
        ax2.hist(processed.flatten(), bins=50, color="green", alpha=0.7)
        ax2.set_title("Processed Histogram", fontweight="bold")
        ax2.set_xlabel("Intensity")
        ax2.set_ylabel("Frequency")
        ax2.grid(alpha=0.3)

        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

        # Pipeline summary
        st.markdown("---")
        st.subheader("üìã Pipeline Summary")

        if st.session_state.prep_operations:
            for i, op in enumerate(st.session_state.prep_operations, 1):
                st.markdown(f"{i}. {op}")
        else:
            st.info("No operations applied")

        # Download
        st.markdown("---")
        st.subheader("Download")

        col1, col2, col3 = st.columns(3)

        with col1:
            # Download as NumPy
            npy_buffer = io.BytesIO()
            np.save(npy_buffer, processed)
            npy_bytes = npy_buffer.getvalue()

            st.download_button(
                label="üì• Download Image (.npy)",
                data=npy_bytes,
                file_name="preprocessed_image.npy",
                mime="application/octet-stream",
            )

        with col2:
            # Download as PNG
            fig_save = plt.figure(figsize=(8, 8))
            plt.imshow(processed, cmap="gray")
            plt.axis("off")

            img_buffer = io.BytesIO()
            plt.savefig(img_buffer, format="png", bbox_inches="tight", dpi=150)
            img_buffer.seek(0)
            plt.close()

            st.download_button(
                label="üì• Download Image (.png)",
                data=img_buffer,
                file_name="preprocessed_image.png",
                mime="image/png",
            )

        with col3:
            # Download pipeline config
            import json

            config = {"operations": st.session_state.prep_operations, "parameters": {}}

            if normalize_enabled:
                config["parameters"]["normalize"] = {"method": norm_method}
                if norm_method == "Percentile Clipping":
                    config["parameters"]["normalize"]["percentiles"] = (
                        lower_p,
                        upper_p,
                    )

            if denoise_enabled:
                config["parameters"]["denoise"] = {"method": denoise_method}
                if denoise_method == "Gaussian":
                    config["parameters"]["denoise"]["sigma"] = sigma
                else:
                    config["parameters"]["denoise"]["kernel_size"] = kernel_size

            if resize_enabled:
                config["parameters"]["resize"] = {"size": target_size}

            if enhance_enabled:
                config["parameters"]["enhance"] = {"method": enhance_method}
                if enhance_method == "CLAHE":
                    config["parameters"]["enhance"]["clip_limit"] = clip_limit
                elif enhance_method == "Gamma Correction":
                    config["parameters"]["enhance"]["gamma"] = gamma

            json_str = json.dumps(config, indent=2)

            st.download_button(
                label="üì• Download Config (.json)",
                data=json_str,
                file_name="pipeline_config.json",
                mime="application/json",
            )

else:
    st.info("üëÜ Upload an image to start preprocessing")

    st.markdown("---")
    st.subheader("Quick Guide")

    st.markdown(
        """
    **How to use:**
    1. Upload medical image
    2. Enable desired operations (sidebar)
    3. Adjust parameters for each operation
    4. Click "Apply Preprocessing"
    5. Compare before/after results
    6. Download processed image
    
    **Recommended workflow:**
    - Start with **Normalize** (Min-Max)
    - Add **Denoise** if image is noisy
    - Use **Resize** to standardize size
    - Apply **CLAHE** for better contrast
    
    **Tips:**
    - Apply one operation at a time to see effect
    - Check histogram to verify normalization
    - Save pipeline config for reproducibility
    - Use Percentile Clipping for outlier-heavy images
    """
    )

# Footer
st.markdown("---")
st.caption(" Tip: Apply operations in order - Normalize ‚Üí Denoise ‚Üí Resize ‚Üí Enhance")
